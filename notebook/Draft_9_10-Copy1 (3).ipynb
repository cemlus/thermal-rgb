{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab88289a-7d98-4efa-87ab-b8343fbca8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import transforms, models\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc5025a2-3b12-4e26-93de-71f36b938a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov  1 08:29:05 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.06             Driver Version: 535.183.06   CUDA Version: 12.6     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          Off | 00000000:4E:00.0 Off |                   On |\n",
      "| N/A   38C    P0              91W / 400W |                  N/A |     N/A      Default |\n",
      "|                                         |                      |              Enabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "\n",
      "+---------------------------------------------------------------------------------------+\n",
      "| MIG devices:                                                                          |\n",
      "+------------------+--------------------------------+-----------+-----------------------+\n",
      "| GPU  GI  CI  MIG |                   Memory-Usage |        Vol|      Shared           |\n",
      "|      ID  ID  Dev |                     BAR1-Usage | SM     Unc| CE ENC DEC OFA JPG    |\n",
      "|                  |                                |        ECC|                       |\n",
      "|==================+================================+===========+=======================|\n",
      "|  0    2   0   0  |              37MiB / 40192MiB  | 42      0 |  3   0    2    0    0 |\n",
      "|                  |               0MiB / 65535MiB  |           |                       |\n",
      "+------------------+--------------------------------+-----------+-----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a974c9db-6499-410c-a2fe-1a5c67508967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found RGB: 148828 | Thermal: 148828\n",
      "‚úÖ Using pairs: 148828\n"
     ]
    }
   ],
   "source": [
    "# Root path = inner dataset folder\n",
    "root = os.path.join(\"dataset_1-6-2024\", \"dataset_1-6-2024\")\n",
    "rgb_dir     = os.path.join(root, \"class1\")  # RGB\n",
    "thermal_dir = os.path.join(root, \"class2\")  # Thermal\n",
    "\n",
    "def list_images(d):\n",
    "    exts = (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\",\"*.tif\",\"*.tiff\")\n",
    "    files = []\n",
    "    for e in exts:\n",
    "        files.extend(glob.glob(os.path.join(d, e)))\n",
    "    return sorted(files)\n",
    "\n",
    "rgb_files     = list_images(rgb_dir)\n",
    "thermal_files = list_images(thermal_dir)\n",
    "print(f\"Found RGB: {len(rgb_files)} | Thermal: {len(thermal_files)}\")\n",
    "\n",
    "# Direct pairing (no skip/verification) ‚Äî keep original pairing logic\n",
    "n = min(len(rgb_files), len(thermal_files))\n",
    "rgb_files = rgb_files[:n]\n",
    "thermal_files = thermal_files[:n]\n",
    "print(f\"‚úÖ Using pairs: {len(thermal_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7492f03-3200-42b7-86f0-48e067f41fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThermalRGBDataset(Dataset):\n",
    "    \"\"\"\n",
    "    - Reads paired thermal and RGB images.\n",
    "    - Applies synchronized augmentations for better training.\n",
    "    - Normalizes images to the [-1, 1] range.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, thermal_files, rgb_files, image_size=256, resize_to=286, augment=True):\n",
    "        n = min(len(thermal_files), len(rgb_files))\n",
    "        self.t_files = list(thermal_files[:n])\n",
    "        self.r_files = list(rgb_files[:n])\n",
    "        self.img_size = image_size\n",
    "        self.resize_to = resize_to\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.t_files)\n",
    "\n",
    "    def _normalize(self, t, channels):\n",
    "        return TF.normalize(t, mean=[0.5] * channels, std=[0.5] * channels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t_img = Image.open(self.t_files[idx]).convert(\"L\")\n",
    "        r_img = Image.open(self.r_files[idx]).convert(\"RGB\")\n",
    "\n",
    "        t_img = TF.resize(t_img, [self.resize_to, self.resize_to], antialias=True)\n",
    "        r_img = TF.resize(r_img, [self.resize_to, self.resize_to], antialias=True)\n",
    "\n",
    "        if self.augment:\n",
    "            i, j, h, w = transforms.RandomCrop.get_params(r_img, output_size=(self.img_size, self.img_size))\n",
    "            t_img = TF.crop(t_img, i, j, h, w)\n",
    "            r_img = TF.crop(r_img, i, j, h, w)\n",
    "\n",
    "            if random.random() < 0.5:\n",
    "                t_img = TF.hflip(t_img)\n",
    "                r_img = TF.hflip(r_img)\n",
    "\n",
    "        else:\n",
    "            t_img = TF.center_crop(t_img, [self.img_size, self.img_size])\n",
    "            r_img = TF.center_crop(r_img, [self.img_size, self.img_size])\n",
    "\n",
    "        t = TF.to_tensor(t_img)\n",
    "        r = TF.to_tensor(r_img)\n",
    "\n",
    "        t = self._normalize(t, 1)\n",
    "        r = self._normalize(r, 3)\n",
    "\n",
    "        return t, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a5f15aa-0ad1-440f-b42b-209edf0ee039",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_120065/1148126130.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(split_file)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import multiprocessing\n",
    "\n",
    "dataset = ThermalRGBDataset(thermal_files, rgb_files, image_size=256, resize_to=286, augment=True)\n",
    "\n",
    "split_file = \"train_val_split.pt\"\n",
    "recreate_split = not os.path.exists(split_file)\n",
    "\n",
    "if not recreate_split:\n",
    "    try:\n",
    "        data = torch.load(split_file)\n",
    "        train_idx, val_idx = data[\"train\"], data[\"val\"]\n",
    "        if max(train_idx + val_idx) >= len(dataset) or len(train_idx) + len(val_idx) != len(dataset):\n",
    "            recreate_split = True\n",
    "    except:\n",
    "        recreate_split = True\n",
    "\n",
    "if recreate_split:\n",
    "    idx = torch.randperm(len(dataset)).tolist()\n",
    "    trn = int(0.9 * len(dataset))\n",
    "    train_idx, val_idx = idx[:trn], idx[trn:]\n",
    "    torch.save({\"train\": train_idx, \"val\": val_idx}, split_file)\n",
    "\n",
    "train_set = Subset(dataset, train_idx)\n",
    "val_set = Subset(dataset, val_idx)\n",
    "\n",
    "# 10-way split for progressive training\n",
    "parts = 10\n",
    "sizes = [len(train_set) // parts] * (parts - 1)\n",
    "sizes.append(len(train_set) - sum(sizes))\n",
    "train_parts = random_split(train_set, sizes)\n",
    "\n",
    "def make_loader(subset, batch_size=32, shuffle=True):\n",
    "    num_workers = 3\n",
    "    return DataLoader(\n",
    "        subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        prefetch_factor=4,\n",
    "        persistent_workers=True,\n",
    "    )\n",
    "\n",
    "val_loader = make_loader(val_set, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8697d09a-9016-4c3f-838b-eac8e36217a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- GENERATOR WARM-UP ---\n",
    "# # Only run this if starting from scratch\n",
    "# if start_part == 1:\n",
    "#     print(\"üöÄ Starting Generator Warm-up for 5 epochs...\")\n",
    "#     warmup_epochs = 5\n",
    "#     gen.train()\n",
    "#     # Use the first part of the data for pre-training\n",
    "#     warmup_loader = make_loader(train_parts[0], batch_size=32, shuffle=True)\n",
    "\n",
    "#     for epoch in range(warmup_epochs):\n",
    "#         for thermal_img, real_rgb in warmup_loader:\n",
    "#             thermal_img, real_rgb = thermal_img.to(device), real_rgb.to(device)\n",
    "            \n",
    "#             opt_gen.zero_grad()\n",
    "#             with torch.amp.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
    "#                 fake_rgb = gen(thermal_img)\n",
    "#                 # Calculate only reconstruction losses\n",
    "#                 loss_g_l1 = l1(fake_rgb, real_rgb) * lambda_L1\n",
    "#                 loss_g_perceptual = perceptual_loss(fake_rgb, real_rgb) * lambda_perceptual\n",
    "#                 warmup_loss = loss_g_l1 + loss_g_perceptual\n",
    "            \n",
    "#             scaler.scale(warmup_loss).backward()\n",
    "#             scaler.step(opt_gen)\n",
    "#             scaler.update()\n",
    "        \n",
    "#         print(f\"Warm-up Epoch {epoch+1}/{warmup_epochs}, Loss: {warmup_loss.item():.4f}\")\n",
    "#     print(\"‚úÖ Generator Warm-up complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5808f96-fd67-40f4-a878-7d9b4b767f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualConv(nn.Module):\n",
    "    def __init__(self, in_c, out_c, norm=True):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(in_c, out_c, 1, 1, 0, bias=False) if in_c != out_c else None\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, 3, 1, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_c) if norm else nn.Identity()\n",
    "        self.act = nn.GELU()\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c, 3, 1, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_c) if norm else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x if self.proj is None else self.proj(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.act(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        return self.act(out + identity)\n",
    "\n",
    "\n",
    "class DenseUNetGenerator(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=3, base=32):\n",
    "        super().__init__()\n",
    "        self.down1 = self.down_block(in_channels, base, norm=False)\n",
    "        self.down2 = self.down_block(base, base * 2)\n",
    "        self.down3 = self.down_block(base * 2, base * 4)\n",
    "        self.down4 = self.down_block(base * 4, base * 8)\n",
    "        self.down5 = self.down_block(base * 8, base * 8)\n",
    "        self.down6 = self.down_block(base * 8, base * 8)\n",
    "        self.down7 = self.down_block(base * 8, base * 8)\n",
    "        self.down8 = self.down_block(base * 8, base * 8, norm=False)\n",
    "\n",
    "        self.up1 = self.up_block(base * 8, base * 8, drop=True)\n",
    "        self.up2 = self.up_block(base * 16, base * 8, drop=True)\n",
    "        self.up3 = self.up_block(base * 16, base * 8, drop=True)\n",
    "        self.up4 = self.up_block(base * 16, base * 8)\n",
    "        self.up5 = self.up_block(base * 16, base * 4)\n",
    "        self.up6 = self.up_block(base * 8, base * 2)\n",
    "        self.up7 = self.up_block(base * 4, base)\n",
    "\n",
    "        self.final = nn.Sequential(nn.ConvTranspose2d(base * 2, out_channels, 4, 2, 1, bias=False), nn.Tanh())\n",
    "\n",
    "    def down_block(self, in_c, out_c, norm=True):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_c) if norm else nn.Identity(),\n",
    "            nn.GELU(),\n",
    "            ResidualConv(out_c, out_c, norm=norm),\n",
    "        )\n",
    "\n",
    "    def up_block(self, in_c, out_c, drop=False):\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(in_c, out_c, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.GELU(),\n",
    "            ResidualConv(out_c, out_c),\n",
    "        ]\n",
    "        if drop:\n",
    "            layers.append(nn.Dropout(0.5))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)\n",
    "        d6 = self.down6(d5)\n",
    "        d7 = self.down7(d6)\n",
    "        d8 = self.down8(d7)\n",
    "\n",
    "        u1 = self.up1(d8)\n",
    "        u1 = torch.cat([u1, d7], dim=1)\n",
    "        u2 = self.up2(u1)\n",
    "        u2 = torch.cat([u2, d6], dim=1)\n",
    "        u3 = self.up3(u2)\n",
    "        u3 = torch.cat([u3, d5], dim=1)\n",
    "        u4 = self.up4(u3)\n",
    "        u4 = torch.cat([u4, d4], dim=1)\n",
    "        u5 = self.up5(u4)\n",
    "        u5 = torch.cat([u5, d3], dim=1)\n",
    "        u6 = self.up6(u5)\n",
    "        u6 = torch.cat([u6, d2], dim=1)\n",
    "        u7 = self.up7(u6)\n",
    "        u7 = torch.cat([u7, d1], dim=1)\n",
    "\n",
    "        return self.final(u7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "631e2a45-efc1-4d9d-85ef-21046c30c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBlock(nn.Module):\n",
    "    def __init__(self, in_c, out_c, norm=True, use_spectral=True):\n",
    "        super().__init__()\n",
    "        conv = nn.Conv2d(in_c, out_c, 4, 2, 1, bias=False)\n",
    "        if use_spectral:\n",
    "            conv = nn.utils.spectral_norm(conv)\n",
    "        self.conv = conv\n",
    "        self.bn = nn.BatchNorm2d(out_c) if norm else nn.Identity()\n",
    "        self.act = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.res = ResidualConv(out_c, out_c, norm=norm)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        return self.res(x)\n",
    "\n",
    "\n",
    "class PatchDiscriminatorDense(nn.Module):\n",
    "    def __init__(self, in_channels=4, base=64):\n",
    "        super().__init__()\n",
    "        self.b1 = DBlock(in_channels, base, norm=False, use_spectral=True)\n",
    "        self.b2 = DBlock(base, base * 2, use_spectral=True)\n",
    "        self.b3 = DBlock(base * 2, base * 4, use_spectral=True)\n",
    "        self.b4 = DBlock(base * 4, base * 8, use_spectral=True)\n",
    "        self.b5 = DBlock(base * 8, base * 8, use_spectral=True)\n",
    "\n",
    "        self.features = nn.ModuleList([self.b1, self.b2, self.b3, self.b4, self.b5])\n",
    "\n",
    "        self.out = nn.Conv2d(base * 8, 1, 3, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        features = []\n",
    "        for layer in self.features:\n",
    "            x = layer(x)\n",
    "            if return_features:\n",
    "                features.append(x)\n",
    "        output = self.out(x)\n",
    "        if return_features:\n",
    "            return output, features\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e70ef533-c1f0-48d9-9c02-18841c82f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGPerceptualLoss(nn.Module):\n",
    "    def __init__(self, resize=True):\n",
    "        super(VGGPerceptualLoss, self).__init__()\n",
    "        vgg = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1).features\n",
    "        self.slice1 = nn.Sequential()\n",
    "        self.slice2 = nn.Sequential()\n",
    "        self.slice3 = nn.Sequential()\n",
    "\n",
    "        for x in range(4):\n",
    "            self.slice1.add_module(str(x), vgg[x])\n",
    "        for x in range(4, 9):\n",
    "            self.slice2.add_module(str(x), vgg[x])\n",
    "        for x in range(9, 16):\n",
    "            self.slice3.add_module(str(x), vgg[x])\n",
    "\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        self.l1 = nn.L1Loss()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = (x + 1) / 2\n",
    "        y = (y + 1) / 2\n",
    "\n",
    "        x = self.normalize(x)\n",
    "        y = self.normalize(y)\n",
    "\n",
    "        feat_x1 = self.slice1(x)\n",
    "        feat_y1 = self.slice1(y)\n",
    "        feat_x2 = self.slice2(feat_x1)\n",
    "        feat_y2 = self.slice2(feat_y1)\n",
    "        feat_x3 = self.slice3(feat_x2)\n",
    "        feat_y3 = self.slice3(feat_y2)\n",
    "\n",
    "        loss1 = self.l1(feat_x1, feat_y1)\n",
    "        loss2 = self.l1(feat_x2, feat_y2)\n",
    "        loss3 = self.l1(feat_x3, feat_y3)\n",
    "\n",
    "        return loss1 + loss2 + loss3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3062d301-dfb8-4e95-b117-2bb72c882f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov  1 08:29:07 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.06             Driver Version: 535.183.06   CUDA Version: 12.6     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          Off | 00000000:4E:00.0 Off |                   On |\n",
      "| N/A   37C    P0              90W / 400W |                  N/A |     N/A      Default |\n",
      "|                                         |                      |              Enabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "\n",
      "+---------------------------------------------------------------------------------------+\n",
      "| MIG devices:                                                                          |\n",
      "+------------------+--------------------------------+-----------+-----------------------+\n",
      "| GPU  GI  CI  MIG |                   Memory-Usage |        Vol|      Shared           |\n",
      "|      ID  ID  Dev |                     BAR1-Usage | SM     Unc| CE ENC DEC OFA JPG    |\n",
      "|                  |                                |        ECC|                       |\n",
      "|==================+================================+===========+=======================|\n",
      "|  0    2   0   0  |              37MiB / 40192MiB  | 42      0 |  3   0    2    0    0 |\n",
      "|                  |               0MiB / 65535MiB  |           |                       |\n",
      "+------------------+--------------------------------+-----------+-----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f91bcb6c-e73e-4b89-b5b7-44ef69a60be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Applied weights_init.\n",
      "Params ‚Üí Gen: 25,008,064, Disc: 17,949,440\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR # Import MultiStepLR\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "gen = DenseUNetGenerator().to(device)\n",
    "disc = PatchDiscriminatorDense().to(device)\n",
    "perceptual_loss = VGGPerceptualLoss().to(device)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.Linear)):\n",
    "        nn.init.kaiming_normal_(m.weight, a=0.2, mode=\"fan_in\", nonlinearity=\"leaky_relu\")\n",
    "        if getattr(m, \"bias\", None) is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.ones_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "gen.apply(weights_init)\n",
    "disc.apply(weights_init)\n",
    "print(\"Applied weights_init.\")\n",
    "\n",
    "# --- Final Hyperparameter Balance ---\n",
    "lambda_L1 = 100\n",
    "lambda_perceptual = 0.1\n",
    "lambda_GAN = 0.1\n",
    "epochs_per_part = 100\n",
    "\n",
    "# --- NEW: Define optimizers and schedulers here ---\n",
    "# This ensures they exist for the warm-up and checkpoint loading.\n",
    "opt_gen = torch.optim.Adam(gen.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "opt_disc = torch.optim.Adam(disc.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "scheduler_gen = MultiStepLR(opt_gen, milestones=[30], gamma=0.1)\n",
    "scheduler_disc = MultiStepLR(opt_disc, milestones=[30], gamma=0.1)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# Loss functions\n",
    "criterion_adv = nn.BCEWithLogitsLoss()\n",
    "l1 = nn.L1Loss()\n",
    "\n",
    "# Mixed precision scaler\n",
    "scaler = torch.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
    "\n",
    "def count_params(m):\n",
    "    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Params ‚Üí Gen: {count_params(gen):,}, Disc: {count_params(disc):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ae6b8b0-03fe-4858-b092-3dffaf83a81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resuming training from checkpoint: checkpoints-9_10_latest/checkpoint_part_3_epoch_40.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_120065/1601140584.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(latest_checkpoint_path, map_location=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚û°Ô∏è Resuming from Part 3, Epoch 41\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "checkpoint_dir = \"checkpoints-9_10_latest\" # Make sure this matches your folder name\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "latest_checkpoint_path = None\n",
    "# Filter the list to only include checkpoint files\n",
    "checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.endswith('.pt')]\n",
    "\n",
    "if checkpoint_files:\n",
    "    latest_checkpoint_path = max(\n",
    "        [os.path.join(checkpoint_dir, f) for f in checkpoint_files],\n",
    "        key=os.path.getctime,\n",
    "    )\n",
    "\n",
    "start_part = 1\n",
    "start_epoch = 1\n",
    "\n",
    "if latest_checkpoint_path:\n",
    "    print(f\"‚úÖ Resuming training from checkpoint: {latest_checkpoint_path}\")\n",
    "    checkpoint = torch.load(latest_checkpoint_path, map_location=torch.device(\"cpu\"))\n",
    "\n",
    "    gen.load_state_dict(checkpoint[\"gen_state_dict\"])\n",
    "    disc.load_state_dict(checkpoint[\"disc_state_dict\"])\n",
    "    opt_gen.load_state_dict(checkpoint[\"opt_gen_state_dict\"])\n",
    "    opt_disc.load_state_dict(checkpoint[\"opt_disc_state_dict\"])\n",
    "    val_history = checkpoint.get(\"val_history\", [])\n",
    "    \n",
    "    start_part = checkpoint[\"part\"]\n",
    "    start_epoch = checkpoint.get(\"epoch\", 0) + 1\n",
    "\n",
    "    if start_epoch > epochs_per_part:\n",
    "        start_part += 1\n",
    "        start_epoch = 1\n",
    "    \n",
    "    print(f\"‚û°Ô∏è Resuming from Part {start_part}, Epoch {start_epoch}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚úÖ Starting training from scratch.\")\n",
    "    # --- NEW: Initialize val_history for a fresh start ---\n",
    "    val_history = []\n",
    "    # ----------------------------------------------------\n",
    "    \n",
    "    # This section for generator warm-up will only run on a fresh start\n",
    "    if 'train_parts' in locals() and len(train_parts) > 0:\n",
    "        print(\"\\nüöÄ Starting Generator Warm-up for 5 epochs...\")\n",
    "        warmup_epochs = 5\n",
    "        gen.train()\n",
    "        warmup_loader = make_loader(train_parts[0], batch_size=32, shuffle=True)\n",
    "        for epoch in range(warmup_epochs):\n",
    "            for thermal_img, real_rgb in warmup_loader:\n",
    "                thermal_img, real_rgb = thermal_img.to(device), real_rgb.to(device)\n",
    "                \n",
    "                opt_gen.zero_grad() \n",
    "                \n",
    "                with torch.amp.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
    "                    fake_rgb = gen(thermal_img)\n",
    "                    loss_g_l1 = l1(fake_rgb, real_rgb) * lambda_L1\n",
    "                    loss_g_perceptual = perceptual_loss(fake_rgb, real_rgb) * lambda_perceptual\n",
    "                    warmup_loss = loss_g_l1 + loss_g_perceptual\n",
    "                scaler.scale(warmup_loss).backward()\n",
    "                scaler.step(opt_gen)\n",
    "                scaler.update()\n",
    "            print(f\"Warm-up Epoch {epoch+1}/{warmup_epochs}, Loss: {warmup_loss.item():.4f}\")\n",
    "        print(\"‚úÖ Generator Warm-up complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e0db6c2-b081-4de9-9ea3-c9c14c329a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cell 8\n",
    "# # if hasattr(torch, \"compile\"):\n",
    "    \n",
    "# #     gen = torch.compile(gen)\n",
    "# #     disc = torch.compile(disc)\n",
    "\n",
    "# # Cell 8 (optional compile)\n",
    "# if hasattr(torch, \"compile\"):\n",
    "#     try:\n",
    "#         gen = torch.compile(gen)\n",
    "#         disc = torch.compile(disc)\n",
    "#         print(\"‚úÖ Models compiled with torch.compile()\")\n",
    "#     except Exception as e:\n",
    "#         print(\"‚ö†Ô∏è torch.compile not applied:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2143753-935e-4cc3-becd-6f0ac2dab4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ New Torch-based PSNR, SSIM, and evaluate functions defined.\n",
      "Found existing best model at: checkpoints-9_10_latest/best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_120065/3505740776.py:260: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_checkpoint = torch.load(best_model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming with best_val_psnr: 19.17 dB\n",
      "‚úÖ Helper functions for checkpointing and plotting are defined.\n",
      "\n",
      "==================================================\n",
      "--- Starting Main Training Loop ---\n",
      "Strategy: Train on ONE part, reset optimizers.\n",
      "Resuming from Part: 3, Epoch: 41\n",
      "Tracking Best PSNR (current best: 19.17 dB)\n",
      "Hyperparameters: L1_Œª=100, Perceptual_Œª=0.1, GAN_Œª=0.1\n",
      "Evaluation will run every 20 epochs or on the last epoch of each part.\n",
      "==================================================\n",
      "\n",
      "\n",
      "--- Starting Training on Part 3/10 ---\n",
      "Dataset size: 13394 images\n",
      "‚ú® Resetting optimizers and using MultiStepLR schedule.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 41/100 | Time: 111.17s ---\n",
      "  Train Loss ‚Üí G: 14.6067, D: 0.3064 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 42/100 | Time: 106.27s ---\n",
      "  Train Loss ‚Üí G: 14.4565, D: 0.2677 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 43/100 | Time: 106.15s ---\n",
      "  Train Loss ‚Üí G: 14.3232, D: 0.2657 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 44/100 | Time: 106.06s ---\n",
      "  Train Loss ‚Üí G: 14.2507, D: 0.2589 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 45/100 | Time: 106.04s ---\n",
      "  Train Loss ‚Üí G: 13.9457, D: 0.2674 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 46/100 | Time: 106.11s ---\n",
      "  Train Loss ‚Üí G: 13.9505, D: 0.2641 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 47/100 | Time: 106.24s ---\n",
      "  Train Loss ‚Üí G: 13.9247, D: 0.2561 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 48/100 | Time: 106.14s ---\n",
      "  Train Loss ‚Üí G: 14.2833, D: 0.2528 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 49/100 | Time: 106.06s ---\n",
      "  Train Loss ‚Üí G: 14.1165, D: 0.2456 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 50/100 | Time: 106.12s ---\n",
      "  Train Loss ‚Üí G: 13.8831, D: 0.2475 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 51/100 | Time: 106.20s ---\n",
      "  Train Loss ‚Üí G: 13.7463, D: 0.2361 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 52/100 | Time: 106.17s ---\n",
      "  Train Loss ‚Üí G: 13.7443, D: 0.2467 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 53/100 | Time: 106.13s ---\n",
      "  Train Loss ‚Üí G: 13.5768, D: 0.2487 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 54/100 | Time: 106.11s ---\n",
      "  Train Loss ‚Üí G: 13.6655, D: 0.2422 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 55/100 | Time: 106.21s ---\n",
      "  Train Loss ‚Üí G: 13.4529, D: 0.2498 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 56/100 | Time: 106.17s ---\n",
      "  Train Loss ‚Üí G: 13.5167, D: 0.2414 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 57/100 | Time: 106.04s ---\n",
      "  Train Loss ‚Üí G: 13.3996, D: 0.2368 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 58/100 | Time: 106.04s ---\n",
      "  Train Loss ‚Üí G: 13.4365, D: 0.2504 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 59/100 | Time: 106.05s ---\n",
      "  Train Loss ‚Üí G: 13.4649, D: 0.2382 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 60/100 | Time: 106.06s ---\n",
      "  Train Loss ‚Üí G: 13.4561, D: 0.2431 | LR: 2.0e-04\n",
      "  Running evaluation for epoch 60...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Metrics ‚Üí PSNR: 18.37 dB, SSIM: 0.6001\n",
      "    üíæ Checkpoint saved to checkpoints-9_10_latest/checkpoint_part_3_epoch_60.pt\n",
      "    üóëÔ∏è Removing old checkpoint: checkpoints-9_10_latest/checkpoint_part_2_epoch_100.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 61/100 | Time: 106.19s ---\n",
      "  Train Loss ‚Üí G: 13.9223, D: 0.2310 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 62/100 | Time: 106.06s ---\n",
      "  Train Loss ‚Üí G: 13.5913, D: 0.2266 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 63/100 | Time: 106.13s ---\n",
      "  Train Loss ‚Üí G: 13.3468, D: 0.2503 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 64/100 | Time: 106.01s ---\n",
      "  Train Loss ‚Üí G: 13.2467, D: 0.2511 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 65/100 | Time: 106.03s ---\n",
      "  Train Loss ‚Üí G: 13.6039, D: 0.2228 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 66/100 | Time: 106.15s ---\n",
      "  Train Loss ‚Üí G: 13.6897, D: 0.2377 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 67/100 | Time: 106.14s ---\n",
      "  Train Loss ‚Üí G: 13.3568, D: 0.2432 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 68/100 | Time: 106.03s ---\n",
      "  Train Loss ‚Üí G: 13.2897, D: 0.2288 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 69/100 | Time: 106.00s ---\n",
      "  Train Loss ‚Üí G: 13.3227, D: 0.2285 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 70/100 | Time: 105.99s ---\n",
      "  Train Loss ‚Üí G: 13.1974, D: 0.2470 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 71/100 | Time: 105.98s ---\n",
      "  Train Loss ‚Üí G: 12.6360, D: 0.1728 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 72/100 | Time: 106.12s ---\n",
      "  Train Loss ‚Üí G: 12.7469, D: 0.1766 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 73/100 | Time: 106.16s ---\n",
      "  Train Loss ‚Üí G: 12.8643, D: 0.1766 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 74/100 | Time: 106.14s ---\n",
      "  Train Loss ‚Üí G: 12.8526, D: 0.1753 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 75/100 | Time: 106.19s ---\n",
      "  Train Loss ‚Üí G: 12.8707, D: 0.1733 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 76/100 | Time: 106.17s ---\n",
      "  Train Loss ‚Üí G: 12.8830, D: 0.1746 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 77/100 | Time: 106.22s ---\n",
      "  Train Loss ‚Üí G: 12.8691, D: 0.1751 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 78/100 | Time: 106.21s ---\n",
      "  Train Loss ‚Üí G: 12.8557, D: 0.1760 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 79/100 | Time: 106.12s ---\n",
      "  Train Loss ‚Üí G: 12.9188, D: 0.1756 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 80/100 | Time: 106.07s ---\n",
      "  Train Loss ‚Üí G: 12.9002, D: 0.1781 | LR: 2.0e-05\n",
      "  Running evaluation for epoch 80...\n",
      "  Val Metrics ‚Üí PSNR: 18.56 dB, SSIM: 0.6077\n",
      "    üíæ Checkpoint saved to checkpoints-9_10_latest/checkpoint_part_3_epoch_80.pt\n",
      "    üóëÔ∏è Removing old checkpoint: checkpoints-9_10_latest/checkpoint_part_3_epoch_20.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 81/100 | Time: 106.22s ---\n",
      "  Train Loss ‚Üí G: 12.8533, D: 0.1762 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 82/100 | Time: 106.08s ---\n",
      "  Train Loss ‚Üí G: 12.8340, D: 0.1808 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 83/100 | Time: 106.08s ---\n",
      "  Train Loss ‚Üí G: 12.8547, D: 0.1754 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 84/100 | Time: 106.11s ---\n",
      "  Train Loss ‚Üí G: 12.9128, D: 0.1757 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 85/100 | Time: 106.17s ---\n",
      "  Train Loss ‚Üí G: 12.9083, D: 0.1828 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 86/100 | Time: 106.13s ---\n",
      "  Train Loss ‚Üí G: 12.8674, D: 0.1803 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 87/100 | Time: 106.08s ---\n",
      "  Train Loss ‚Üí G: 12.8362, D: 0.1763 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 88/100 | Time: 106.15s ---\n",
      "  Train Loss ‚Üí G: 12.8871, D: 0.1801 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 89/100 | Time: 106.18s ---\n",
      "  Train Loss ‚Üí G: 12.9349, D: 0.1777 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 90/100 | Time: 106.07s ---\n",
      "  Train Loss ‚Üí G: 12.8679, D: 0.1790 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 91/100 | Time: 105.99s ---\n",
      "  Train Loss ‚Üí G: 12.8413, D: 0.1843 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 92/100 | Time: 106.05s ---\n",
      "  Train Loss ‚Üí G: 12.8783, D: 0.1760 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 93/100 | Time: 106.15s ---\n",
      "  Train Loss ‚Üí G: 12.8922, D: 0.1794 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 94/100 | Time: 106.24s ---\n",
      "  Train Loss ‚Üí G: 12.8644, D: 0.1802 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 95/100 | Time: 106.42s ---\n",
      "  Train Loss ‚Üí G: 12.8248, D: 0.1783 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 96/100 | Time: 106.37s ---\n",
      "  Train Loss ‚Üí G: 12.8465, D: 0.1862 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 97/100 | Time: 106.15s ---\n",
      "  Train Loss ‚Üí G: 12.8882, D: 0.1799 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 98/100 | Time: 106.14s ---\n",
      "  Train Loss ‚Üí G: 12.8854, D: 0.1876 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 99/100 | Time: 106.05s ---\n",
      "  Train Loss ‚Üí G: 12.8763, D: 0.1775 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 3/10 | Epoch 100/100 | Time: 106.00s ---\n",
      "  Train Loss ‚Üí G: 12.8855, D: 0.1844 | LR: 2.0e-05\n",
      "  Running evaluation for epoch 100...\n",
      "  Val Metrics ‚Üí PSNR: 18.64 dB, SSIM: 0.6101\n",
      "    üíæ Checkpoint saved to checkpoints-9_10_latest/checkpoint_part_3_epoch_100.pt\n",
      "    üóëÔ∏è Removing old checkpoint: checkpoints-9_10_latest/checkpoint_part_3_epoch_40.pt\n",
      "\n",
      "--- Starting Training on Part 4/10 ---\n",
      "Dataset size: 13394 images\n",
      "‚ú® Resetting optimizers and using MultiStepLR schedule.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 1/100 | Time: 106.55s ---\n",
      "  Train Loss ‚Üí G: 14.4341, D: 0.2553 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 2/100 | Time: 106.18s ---\n",
      "  Train Loss ‚Üí G: 14.3029, D: 0.2469 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 3/100 | Time: 106.25s ---\n",
      "  Train Loss ‚Üí G: 14.0820, D: 0.2558 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 4/100 | Time: 106.15s ---\n",
      "  Train Loss ‚Üí G: 13.9755, D: 0.2326 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 5/100 | Time: 106.19s ---\n",
      "  Train Loss ‚Üí G: 13.7462, D: 0.2399 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 6/100 | Time: 106.25s ---\n",
      "  Train Loss ‚Üí G: 13.8698, D: 0.2251 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 7/100 | Time: 106.17s ---\n",
      "  Train Loss ‚Üí G: 13.8274, D: 0.2345 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 8/100 | Time: 105.99s ---\n",
      "  Train Loss ‚Üí G: 14.0650, D: 0.2152 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 9/100 | Time: 106.11s ---\n",
      "  Train Loss ‚Üí G: 13.6194, D: 0.2442 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 10/100 | Time: 106.11s ---\n",
      "  Train Loss ‚Üí G: 13.8879, D: 0.2083 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 11/100 | Time: 106.00s ---\n",
      "  Train Loss ‚Üí G: 13.9925, D: 0.2194 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 12/100 | Time: 105.98s ---\n",
      "  Train Loss ‚Üí G: 13.8384, D: 0.2226 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 13/100 | Time: 106.16s ---\n",
      "  Train Loss ‚Üí G: 13.5208, D: 0.2349 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 14/100 | Time: 106.18s ---\n",
      "  Train Loss ‚Üí G: 13.4092, D: 0.2201 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 15/100 | Time: 106.21s ---\n",
      "  Train Loss ‚Üí G: 13.4368, D: 0.2186 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 16/100 | Time: 106.24s ---\n",
      "  Train Loss ‚Üí G: 13.4692, D: 0.2161 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 17/100 | Time: 106.15s ---\n",
      "  Train Loss ‚Üí G: 13.3854, D: 0.2216 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 18/100 | Time: 106.11s ---\n",
      "  Train Loss ‚Üí G: 13.1872, D: 0.2163 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 19/100 | Time: 106.43s ---\n",
      "  Train Loss ‚Üí G: 13.4149, D: 0.2222 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 20/100 | Time: 106.03s ---\n",
      "  Train Loss ‚Üí G: 13.3674, D: 0.2239 | LR: 2.0e-04\n",
      "  Running evaluation for epoch 20...\n",
      "  Val Metrics ‚Üí PSNR: 18.96 dB, SSIM: 0.6293\n",
      "    üíæ Checkpoint saved to checkpoints-9_10_latest/checkpoint_part_4_epoch_20.pt\n",
      "    üóëÔ∏è Removing old checkpoint: checkpoints-9_10_latest/checkpoint_part_3_epoch_60.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 21/100 | Time: 106.12s ---\n",
      "  Train Loss ‚Üí G: 13.4264, D: 0.2230 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 22/100 | Time: 106.07s ---\n",
      "  Train Loss ‚Üí G: 13.2951, D: 0.2141 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 23/100 | Time: 106.09s ---\n",
      "  Train Loss ‚Üí G: 13.4128, D: 0.1930 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 24/100 | Time: 106.15s ---\n",
      "  Train Loss ‚Üí G: 13.2786, D: 0.2133 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 25/100 | Time: 106.25s ---\n",
      "  Train Loss ‚Üí G: 13.1044, D: 0.2400 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 26/100 | Time: 106.06s ---\n",
      "  Train Loss ‚Üí G: 13.2472, D: 0.2005 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 27/100 | Time: 106.03s ---\n",
      "  Train Loss ‚Üí G: 13.1499, D: 0.2091 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 28/100 | Time: 106.04s ---\n",
      "  Train Loss ‚Üí G: 13.1098, D: 0.2366 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 29/100 | Time: 106.10s ---\n",
      "  Train Loss ‚Üí G: 13.1103, D: 0.2063 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 30/100 | Time: 106.09s ---\n",
      "  Train Loss ‚Üí G: 13.4512, D: 0.2010 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 31/100 | Time: 106.10s ---\n",
      "  Train Loss ‚Üí G: 12.8085, D: 0.1714 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 32/100 | Time: 105.96s ---\n",
      "  Train Loss ‚Üí G: 12.8639, D: 0.1802 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 33/100 | Time: 106.08s ---\n",
      "  Train Loss ‚Üí G: 12.8336, D: 0.1735 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 34/100 | Time: 106.02s ---\n",
      "  Train Loss ‚Üí G: 12.8965, D: 0.1749 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 35/100 | Time: 106.10s ---\n",
      "  Train Loss ‚Üí G: 12.8919, D: 0.1748 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 36/100 | Time: 105.98s ---\n",
      "  Train Loss ‚Üí G: 12.8569, D: 0.1727 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 37/100 | Time: 106.11s ---\n",
      "  Train Loss ‚Üí G: 12.8076, D: 0.1718 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 38/100 | Time: 106.22s ---\n",
      "  Train Loss ‚Üí G: 12.8270, D: 0.1735 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 39/100 | Time: 106.10s ---\n",
      "  Train Loss ‚Üí G: 12.7859, D: 0.1729 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 40/100 | Time: 106.05s ---\n",
      "  Train Loss ‚Üí G: 12.8283, D: 0.1734 | LR: 2.0e-05\n",
      "  Running evaluation for epoch 40...\n",
      "  Val Metrics ‚Üí PSNR: 18.69 dB, SSIM: 0.6179\n",
      "    üíæ Checkpoint saved to checkpoints-9_10_latest/checkpoint_part_4_epoch_40.pt\n",
      "    üóëÔ∏è Removing old checkpoint: checkpoints-9_10_latest/checkpoint_part_3_epoch_80.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 41/100 | Time: 106.17s ---\n",
      "  Train Loss ‚Üí G: 12.8416, D: 0.1729 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 42/100 | Time: 106.12s ---\n",
      "  Train Loss ‚Üí G: 12.8540, D: 0.1701 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 43/100 | Time: 106.16s ---\n",
      "  Train Loss ‚Üí G: 12.8114, D: 0.1719 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 44/100 | Time: 106.17s ---\n",
      "  Train Loss ‚Üí G: 12.8160, D: 0.1731 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 45/100 | Time: 106.11s ---\n",
      "  Train Loss ‚Üí G: 12.7743, D: 0.1707 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 46/100 | Time: 106.04s ---\n",
      "  Train Loss ‚Üí G: 12.7838, D: 0.1716 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 47/100 | Time: 106.13s ---\n",
      "  Train Loss ‚Üí G: 12.8499, D: 0.1706 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 48/100 | Time: 106.14s ---\n",
      "  Train Loss ‚Üí G: 12.8390, D: 0.1724 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 49/100 | Time: 106.10s ---\n",
      "  Train Loss ‚Üí G: 12.7931, D: 0.1758 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 50/100 | Time: 106.06s ---\n",
      "  Train Loss ‚Üí G: 12.7599, D: 0.1749 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 51/100 | Time: 106.05s ---\n",
      "  Train Loss ‚Üí G: 12.7685, D: 0.1735 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 52/100 | Time: 106.00s ---\n",
      "  Train Loss ‚Üí G: 12.8043, D: 0.1733 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 53/100 | Time: 105.97s ---\n",
      "  Train Loss ‚Üí G: 12.7852, D: 0.1772 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 54/100 | Time: 106.11s ---\n",
      "  Train Loss ‚Üí G: 12.7741, D: 0.1752 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 55/100 | Time: 106.10s ---\n",
      "  Train Loss ‚Üí G: 12.7971, D: 0.1722 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 56/100 | Time: 105.96s ---\n",
      "  Train Loss ‚Üí G: 12.7592, D: 0.1741 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 57/100 | Time: 106.08s ---\n",
      "  Train Loss ‚Üí G: 12.7480, D: 0.1723 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 58/100 | Time: 106.05s ---\n",
      "  Train Loss ‚Üí G: 12.8057, D: 0.1753 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 59/100 | Time: 106.06s ---\n",
      "  Train Loss ‚Üí G: 12.7692, D: 0.1733 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 91/100 | Time: 106.11s ---\n",
      "  Train Loss ‚Üí G: 12.7646, D: 0.1763 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 92/100 | Time: 106.17s ---\n",
      "  Train Loss ‚Üí G: 12.8635, D: 0.1828 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 93/100 | Time: 106.10s ---\n",
      "  Train Loss ‚Üí G: 12.8274, D: 0.1802 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 94/100 | Time: 106.05s ---\n",
      "  Train Loss ‚Üí G: 12.7940, D: 0.1798 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 95/100 | Time: 106.11s ---\n",
      "  Train Loss ‚Üí G: 12.7810, D: 0.1801 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 4/10 | Epoch 96/100 | Time: 106.19s ---\n",
      "  Train Loss ‚Üí G: 12.7593, D: 0.1839 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 5/10 | Epoch 82/100 | Time: 106.14s ---\n",
      "  Train Loss ‚Üí G: 12.8432, D: 0.1742 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 5/10 | Epoch 83/100 | Time: 106.11s ---\n",
      "  Train Loss ‚Üí G: 12.7912, D: 0.1738 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 5/10 | Epoch 84/100 | Time: 106.24s ---\n",
      "  Train Loss ‚Üí G: 12.7891, D: 0.1716 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 5/10 | Epoch 85/100 | Time: 106.16s ---\n",
      "  Train Loss ‚Üí G: 12.7366, D: 0.1784 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 5/10 | Epoch 86/100 | Time: 106.06s ---\n",
      "  Train Loss ‚Üí G: 12.7546, D: 0.1700 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 5/10 | Epoch 87/100 | Time: 106.07s ---\n",
      "  Train Loss ‚Üí G: 12.8061, D: 0.1767 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 5/10 | Epoch 88/100 | Time: 106.25s ---\n",
      "  Train Loss ‚Üí G: 12.7480, D: 0.1758 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 5/10 | Epoch 89/100 | Time: 106.24s ---\n",
      "  Train Loss ‚Üí G: 12.7081, D: 0.1748 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 5/10 | Epoch 90/100 | Time: 106.14s ---\n",
      "  Train Loss ‚Üí G: 12.7519, D: 0.1715 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 5/10 | Epoch 91/100 | Time: 106.13s ---\n",
      "  Train Loss ‚Üí G: 12.8252, D: 0.1738 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 5/10 | Epoch 92/100 | Time: 106.14s ---\n",
      "  Train Loss ‚Üí G: 12.8210, D: 0.1709 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 5/10 | Epoch 93/100 | Time: 106.20s ---\n",
      "  Train Loss ‚Üí G: 12.8851, D: 0.1777 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 5/10 | Epoch 94/100 | Time: 106.11s ---\n",
      "  Train Loss ‚Üí G: 12.8966, D: 0.1741 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 5/10 | Epoch 95/100 | Time: 106.09s ---\n",
      "  Train Loss ‚Üí G: 12.8456, D: 0.1789 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 5/10 | Epoch 96/100 | Time: 106.21s ---\n",
      "  Train Loss ‚Üí G: 12.8086, D: 0.1740 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 5/10 | Epoch 97/100 | Time: 106.20s ---\n",
      "  Train Loss ‚Üí G: 12.7331, D: 0.1745 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 5/10 | Epoch 98/100 | Time: 106.16s ---\n",
      "  Train Loss ‚Üí G: 12.8202, D: 0.1754 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 5/10 | Epoch 99/100 | Time: 106.11s ---\n",
      "  Train Loss ‚Üí G: 12.9313, D: 0.1756 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 5/10 | Epoch 100/100 | Time: 106.15s ---\n",
      "  Train Loss ‚Üí G: 12.9013, D: 0.1782 | LR: 2.0e-05\n",
      "  Running evaluation for epoch 100...\n",
      "  Val Metrics ‚Üí PSNR: 18.76 dB, SSIM: 0.6181\n",
      "    üíæ Checkpoint saved to checkpoints-9_10_latest/checkpoint_part_5_epoch_100.pt\n",
      "    üóëÔ∏è Removing old checkpoint: checkpoints-9_10_latest/checkpoint_part_5_epoch_40.pt\n",
      "\n",
      "--- Starting Training on Part 6/10 ---\n",
      "Dataset size: 13394 images\n",
      "‚ú® Resetting optimizers and using MultiStepLR schedule.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 1/100 | Time: 106.50s ---\n",
      "  Train Loss ‚Üí G: 14.1000, D: 0.2380 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 2/100 | Time: 106.09s ---\n",
      "  Train Loss ‚Üí G: 13.7721, D: 0.2152 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 3/100 | Time: 106.06s ---\n",
      "  Train Loss ‚Üí G: 13.8178, D: 0.2117 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 4/100 | Time: 106.14s ---\n",
      "  Train Loss ‚Üí G: 13.8037, D: 0.2074 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 5/100 | Time: 106.08s ---\n",
      "  Train Loss ‚Üí G: 13.5427, D: 0.2149 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 17/100 | Time: 106.13s ---\n",
      "  Train Loss ‚Üí G: 13.2684, D: 0.1960 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 18/100 | Time: 106.15s ---\n",
      "  Train Loss ‚Üí G: 13.2438, D: 0.2033 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 19/100 | Time: 106.05s ---\n",
      "  Train Loss ‚Üí G: 12.9470, D: 0.2224 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 20/100 | Time: 106.12s ---\n",
      "  Train Loss ‚Üí G: 13.0519, D: 0.2136 | LR: 2.0e-04\n",
      "  Running evaluation for epoch 20...\n",
      "  Val Metrics ‚Üí PSNR: 18.73 dB, SSIM: 0.6229\n",
      "    üíæ Checkpoint saved to checkpoints-9_10_latest/checkpoint_part_6_epoch_20.pt\n",
      "    üóëÔ∏è Removing old checkpoint: checkpoints-9_10_latest/checkpoint_part_5_epoch_60.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 21/100 | Time: 106.25s ---\n",
      "  Train Loss ‚Üí G: 13.1909, D: 0.2086 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 22/100 | Time: 106.15s ---\n",
      "  Train Loss ‚Üí G: 13.2935, D: 0.1898 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 23/100 | Time: 106.02s ---\n",
      "  Train Loss ‚Üí G: 13.0641, D: 0.1883 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 24/100 | Time: 106.06s ---\n",
      "  Train Loss ‚Üí G: 12.8849, D: 0.2171 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 25/100 | Time: 106.13s ---\n",
      "  Train Loss ‚Üí G: 12.9718, D: 0.2074 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 26/100 | Time: 106.17s ---\n",
      "  Train Loss ‚Üí G: 13.0796, D: 0.1946 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 27/100 | Time: 106.20s ---\n",
      "  Train Loss ‚Üí G: 13.0054, D: 0.2033 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 28/100 | Time: 106.25s ---\n",
      "  Train Loss ‚Üí G: 13.0201, D: 0.1934 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 29/100 | Time: 106.23s ---\n",
      "  Train Loss ‚Üí G: 12.9597, D: 0.1959 | LR: 2.0e-04\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 30/100 | Time: 106.19s ---\n",
      "  Train Loss ‚Üí G: 12.7926, D: 0.2078 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 31/100 | Time: 106.08s ---\n",
      "  Train Loss ‚Üí G: 12.5291, D: 0.1742 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 32/100 | Time: 106.17s ---\n",
      "  Train Loss ‚Üí G: 12.6733, D: 0.1732 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 33/100 | Time: 106.13s ---\n",
      "  Train Loss ‚Üí G: 12.6773, D: 0.1757 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 34/100 | Time: 106.36s ---\n",
      "  Train Loss ‚Üí G: 12.5549, D: 0.1694 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 35/100 | Time: 106.11s ---\n",
      "  Train Loss ‚Üí G: 12.7329, D: 0.1710 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 36/100 | Time: 106.13s ---\n",
      "  Train Loss ‚Üí G: 12.7329, D: 0.1693 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 37/100 | Time: 106.30s ---\n",
      "  Train Loss ‚Üí G: 12.6048, D: 0.1740 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 38/100 | Time: 106.10s ---\n",
      "  Train Loss ‚Üí G: 12.6546, D: 0.1688 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 39/100 | Time: 106.04s ---\n",
      "  Train Loss ‚Üí G: 12.6848, D: 0.1690 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 40/100 | Time: 106.05s ---\n",
      "  Train Loss ‚Üí G: 12.6592, D: 0.1756 | LR: 2.0e-05\n",
      "  Running evaluation for epoch 40...\n",
      "  Val Metrics ‚Üí PSNR: 18.99 dB, SSIM: 0.6265\n",
      "    üíæ Checkpoint saved to checkpoints-9_10_latest/checkpoint_part_6_epoch_40.pt\n",
      "    üóëÔ∏è Removing old checkpoint: checkpoints-9_10_latest/checkpoint_part_5_epoch_80.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 41/100 | Time: 106.10s ---\n",
      "  Train Loss ‚Üí G: 12.5814, D: 0.1678 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 42/100 | Time: 106.06s ---\n",
      "  Train Loss ‚Üí G: 12.6800, D: 0.1673 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 43/100 | Time: 106.08s ---\n",
      "  Train Loss ‚Üí G: 12.7373, D: 0.1699 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 44/100 | Time: 106.11s ---\n",
      "  Train Loss ‚Üí G: 12.7050, D: 0.1679 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch Summary: Part 6/10 | Epoch 45/100 | Time: 106.09s ---\n",
      "  Train Loss ‚Üí G: 12.7182, D: 0.1668 | LR: 2.0e-05\n",
      "  Skipping evaluation, checkpointing, and graphing for this epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Part 6/10 | Epoch 46/100:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 319/419 [01:20<00:25,  3.97it/s, D_Loss=0.1635, G_L1=11.5379, G_Loss=13.1101]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import MultiStepLR # Make sure this is imported\n",
    "from math import exp\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Assume these are defined in a previous cell ---\n",
    "# gen, disc, criterion_adv, l1, perceptual_loss, scaler\n",
    "# lambda_GAN, lambda_L1, lambda_perceptual\n",
    "# train_parts, val_loader, make_loader\n",
    "# start_part, start_epoch, epochs_per_part\n",
    "# device\n",
    "# --------------------------------------------------\n",
    "\n",
    "# ==============================================================================\n",
    "# CELL 1: TORCH-BASED EVALUATION METRICS\n",
    "# ==============================================================================\n",
    "\n",
    "def denorm01(x):\n",
    "    \"\"\"Denormalizes from [-1, 1] to [0, 1]\"\"\"\n",
    "    return (x * 0.5 + 0.5).clamp(0, 1)\n",
    "\n",
    "def psnr_torch(img1, img2, data_range=1.0):\n",
    "    \"\"\"\n",
    "    Calculates PSNR for a batch of images (range [0, 1]).\n",
    "    \"\"\"\n",
    "    # img1 and img2 have shape [B, C, H, W]\n",
    "    mse = F.mse_loss(img1, img2)\n",
    "    psnr_val = 20 * torch.log10(data_range / torch.sqrt(mse))\n",
    "    return psnr_val\n",
    "\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size//2)**2 / float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss / gauss.sum()\n",
    "\n",
    "def create_window(window_size, channel=1):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()\n",
    "    return window\n",
    "\n",
    "def ssim_torch(img1, img2, window_size=11, window=None, size_average=True, val_range=1.0):\n",
    "    \"\"\"\n",
    "    Calculates SSIM for a batch of images (range [0, 1]).\n",
    "    \"\"\"\n",
    "    (_, channel, _, _) = img1.size()\n",
    "    \n",
    "    if window is None:\n",
    "        real_window = create_window(window_size, channel).to(img1.device)\n",
    "    else:\n",
    "        real_window = window.to(img1.device)\n",
    "\n",
    "    K1 = 0.01\n",
    "    K2 = 0.03\n",
    "    L = val_range\n",
    "    C1 = (K1 * L) ** 2\n",
    "    C2 = (K2 * L) ** 2\n",
    "\n",
    "    mu1 = F.conv2d(img1, real_window, padding=window_size//2, groups=channel)\n",
    "    mu2 = F.conv2d(img2, real_window, padding=window_size//2, groups=channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1 * img1, real_window, padding=window_size//2, groups=channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, real_window, padding=window_size//2, groups=channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1 * img2, real_window, padding=window_size//2, groups=channel) - mu1_mu2\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(gen, loader, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    NEW fast evaluation function using torch-based metrics.\n",
    "    [FIXED for AMP/Half-precision mismatch]\n",
    "    \"\"\"\n",
    "    gen.eval()\n",
    "    psnr_sum = 0.0\n",
    "    ssim_sum = 0.0\n",
    "    n = 0\n",
    "    \n",
    "    # Pre-create the SSIM window (in float32) and move it to the device once\n",
    "    ssim_window = create_window(11, 3).to(device) # 3 channels for RGB\n",
    "\n",
    "    for t, r in loader:\n",
    "        t, r = t.to(device), r.to(device)\n",
    "        \n",
    "        # --- ONLY autocast the model inference ---\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
    "            f = gen(t) # f will be float16\n",
    "        \n",
    "        # --- Convert BOTH images to float32 for metrics ---\n",
    "        r_denorm = denorm01(r)  # r is already float32\n",
    "        \n",
    "        # *** THE FIX IS HERE ***\n",
    "        # Cast f from float16 back to float32 before denorming and calculating metrics\n",
    "        f_denorm = denorm01(f.float()) \n",
    "        \n",
    "        # Now, r_denorm, f_denorm, and ssim_window are all float32\n",
    "        \n",
    "        # Calculate metrics for the whole batch on the GPU\n",
    "        batch_size = t.size(0)\n",
    "        psnr_sum += psnr_torch(r_denorm, f_denorm, data_range=1.0).item() * batch_size\n",
    "        ssim_sum += ssim_torch(r_denorm, f_denorm, window=ssim_window, val_range=1.0).item() * batch_size\n",
    "        n += batch_size\n",
    "        \n",
    "    # Return the average\n",
    "    return psnr_sum / max(1, n), ssim_sum / max(1, n)\n",
    "\n",
    "print(\"‚úÖ New Torch-based PSNR, SSIM, and evaluate functions defined.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# CELL 2: PLOTTING & CHECKPOINTING HELPERS\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Directories ---\n",
    "checkpoint_dir = \"checkpoints-9_10_latest\"\n",
    "graph_dir = \"graphs-9_10_latest\"\n",
    "best_model_path = os.path.join(checkpoint_dir, \"best_model.pt\")\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "os.makedirs(graph_dir, exist_ok=True)\n",
    "\n",
    "def plot_losses(history, save_path):\n",
    "    \"\"\"\n",
    "    Plots and saves the training history.  \n",
    "    Handles gaps in validation data (where psnr/ssim are None).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Extract data\n",
    "    epochs = list(range(len(history))) # Use simple integer indices for plotting\n",
    "    epoch_labels = [f\"{h['part']}-{h['epoch']}\" for h in history]\n",
    "    \n",
    "    # These will contain None for skipped epochs, which plt.plot handles correctly\n",
    "    psnr = [h['psnr'] for h in history]  \n",
    "    ssim = [h['ssim'] for h in history]\n",
    "    g_loss = [h['g_loss'] for h in history]\n",
    "    d_loss = [h['d_loss'] for h in history]\n",
    "    \n",
    "    # Get indices *only* where validation was actually run\n",
    "    val_indices = [i for i, h in enumerate(history) if h['psnr'] is not None]\n",
    "    val_labels = [epoch_labels[i] for i in val_indices]\n",
    "\n",
    "    # Plot PSNR\n",
    "    plt.subplot(2, 2, 1)\n",
    "    # Plot will create breaks for 'None' values\n",
    "    plt.plot(epochs, psnr, label='Validation PSNR', color='blue', marker='o', linestyle='-')\n",
    "    plt.title('Validation PSNR (Higher is Better)')\n",
    "    plt.xlabel('Epoch (Part-Epoch)')\n",
    "    plt.ylabel('PSNR (dB)')\n",
    "    if len(val_indices) > 0: # Set ticks only to evaluated points\n",
    "           plt.xticks(ticks=val_indices, labels=val_labels, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot SSIM\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(epochs, ssim, label='Validation SSIM', color='green', marker='o', linestyle='-')\n",
    "    plt.title('Validation SSIM (Higher is Better)')\n",
    "    plt.xlabel('Epoch (Part-Epoch)')\n",
    "    plt.ylabel('SSIM')\n",
    "    if len(val_indices) > 0: # Set ticks only to evaluated points\n",
    "           plt.xticks(ticks=val_indices, labels=val_labels, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot Generator Loss (runs every epoch)\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(epochs, g_loss, label='Train Generator Loss', color='red')\n",
    "    plt.title('Train Generator Loss (Lower is Better)')\n",
    "    plt.xlabel('Epoch (Part-Epoch)')\n",
    "    # Set ticks to match validation for readability\n",
    "    if len(val_indices) > 0:  \n",
    "           plt.xticks(ticks=val_indices, labels=val_labels, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot Discriminator Loss (runs every epoch)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(epochs, d_loss, label='Train Discriminator Loss', color='purple')\n",
    "    plt.title('Train Discriminator Loss (Lower is Better)')\n",
    "    plt.xlabel('Epoch (Part-Epoch)')\n",
    "    # Set ticks to match validation for readability\n",
    "    if len(val_indices) > 0:\n",
    "           plt.xticks(ticks=val_indices, labels=val_labels, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    # plt.show() # Show plot in notebook\n",
    "    plt.close()\n",
    "\n",
    "def save_checkpoint(state, is_best, part, epoch):\n",
    "    \"\"\"\n",
    "    Saves the current model state and manages checkpoint rotation.\n",
    "    Keeps only the 3 latest checkpoints and the single best model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Save the \"best\" model if this is it\n",
    "        if is_best:\n",
    "            torch.save(state, best_model_path)\n",
    "            print(f\"    *** New Best Model! Saved to {best_model_path} ***\")\n",
    "        \n",
    "        # 2. Save the \"latest\" checkpoint for this epoch\n",
    "        filename = f\"checkpoint_part_{part}_epoch_{epoch}.pt\"\n",
    "        latest_path = os.path.join(checkpoint_dir, filename)\n",
    "        torch.save(state, latest_path)\n",
    "        print(f\"    üíæ Checkpoint saved to {latest_path}\")\n",
    "\n",
    "        # 3. Clean up old checkpoints (keep only 3 latest)\n",
    "        checkpoints = sorted(\n",
    "            glob.glob(os.path.join(checkpoint_dir, \"checkpoint_part_*.pt\")), \n",
    "            key=os.path.getmtime\n",
    "        )\n",
    "        \n",
    "        if len(checkpoints) > 3:\n",
    "            for cp_path in checkpoints[:-3]:\n",
    "                print(f\"    üóëÔ∏è Removing old checkpoint: {cp_path}\")\n",
    "                try:\n",
    "                    os.remove(cp_path)\n",
    "                    \n",
    "                    # Also remove the corresponding graph\n",
    "                    part_epoch_str = cp_path.split('checkpoint_')[-1].split('.pt')[0]\n",
    "                    graph_to_remove = os.path.join(graph_dir, f\"graph_{part_epoch_str}.png\")\n",
    "                    if os.path.exists(graph_to_remove):\n",
    "                        os.remove(graph_to_remove)\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"    Error removing old file {cp_path} or its graph: {e}\")\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"    Error during save_checkpoint: {e}\")\n",
    "\n",
    "# --- Initialize History & Load Best Validation Metric ---\n",
    "\n",
    "# IMPORTANT: If you are resuming training, you must load 'val_history' \n",
    "# from your checkpoint in the *previous* cell, along with start_part/start_epoch.\n",
    "# If this is a new run, we'll create an empty list.\n",
    "if 'val_history' not in globals():\n",
    "    print(\"Initializing new 'val_history' list.\")\n",
    "    val_history = []\n",
    "\n",
    "best_val_psnr = -1.0\n",
    "if os.path.exists(best_model_path):\n",
    "    try:\n",
    "        print(f\"Found existing best model at: {best_model_path}\")\n",
    "        best_checkpoint = torch.load(best_model_path, map_location=device)\n",
    "        if 'val_history' in best_checkpoint and len(best_checkpoint['val_history']) > 0:\n",
    "             # Find the max PSNR from history, filtering out None values\n",
    "             valid_psnrs = [h['psnr'] for h in best_checkpoint['val_history'] if h['psnr'] is not None]\n",
    "             if valid_psnrs:\n",
    "                   best_val_psnr = max(valid_psnrs)\n",
    "        print(f\"Resuming with best_val_psnr: {best_val_psnr:.2f} dB\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not read best_val_psnr from best model: {e}. Starting with -1.0.\")\n",
    "\n",
    "print(\"‚úÖ Helper functions for checkpointing and plotting are defined.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# CELL 3: MAIN TRAINING LOOP (Using \"Perfect\" Original Logic)\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"--- Starting Main Training Loop ---\")\n",
    "print(f\"Strategy: Train on ONE part, reset optimizers.\")\n",
    "print(f\"Resuming from Part: {start_part}, Epoch: {start_epoch}\")\n",
    "print(f\"Tracking Best PSNR (current best: {best_val_psnr:.2f} dB)\")\n",
    "print(f\"Hyperparameters: L1_Œª={lambda_L1}, Perceptual_Œª={lambda_perceptual}, GAN_Œª={lambda_GAN}\")\n",
    "print(\"Evaluation will run every 20 epochs or on the last epoch of each part.\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# --- Loop based on your ORIGINAL \"perfect\" code ---\n",
    "for part_idx in range(start_part, len(train_parts) + 1):\n",
    "    if part_idx > len(train_parts):\n",
    "        break\n",
    "    \n",
    "    # --- FINAL STRATEGY: Train on ONLY the current part (from original code) ---\n",
    "    train_loader = make_loader(train_parts[part_idx - 1], batch_size=32, shuffle=True)\n",
    "    print(f\"\\n--- Starting Training on Part {part_idx}/{len(train_parts)} ---\")\n",
    "    print(f\"Dataset size: {len(train_loader.dataset)} images\")\n",
    "\n",
    "    # --- Reset optimizers and use the Scheduler (from original code) ---\n",
    "    print(\"‚ú® Resetting optimizers and using MultiStepLR schedule.\")\n",
    "    opt_gen = torch.optim.Adam(gen.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    opt_disc = torch.optim.Adam(disc.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    # This scheduler will drop the LR at epoch 30\n",
    "    scheduler_gen = MultiStepLR(opt_gen, milestones=[30], gamma=0.1) \n",
    "    scheduler_disc = MultiStepLR(opt_disc, milestones=[30], gamma=0.1)\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    for epoch in range(start_epoch, epochs_per_part + 1):\n",
    "        gen.train()\n",
    "        disc.train()\n",
    "        \n",
    "        epoch_start_time = time.time()\n",
    "        g_loss_sum = 0.0\n",
    "        d_loss_sum = 0.0\n",
    "        \n",
    "        loop = tqdm(train_loader, desc=f\"Part {part_idx}/{len(train_parts)} | Epoch {epoch}/{epochs_per_part}\", leave=False)\n",
    "\n",
    "        for step, (thermal_img, real_rgb) in enumerate(loop, 1):\n",
    "            thermal_img, real_rgb = thermal_img.to(device), real_rgb.to(device)\n",
    "            \n",
    "            # ---------------------\n",
    "            #  Train Discriminator (FROM ORIGINAL \"PERFECT\" CODE)\n",
    "            # ---------------------\n",
    "            opt_disc.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
    "                fake_rgb = gen(thermal_img)\n",
    "                disc_real_input = torch.cat((thermal_img, real_rgb), 1)\n",
    "                disc_fake_input = torch.cat((thermal_img, fake_rgb.detach()), 1)\n",
    "                disc_real_output = disc(disc_real_input)\n",
    "                disc_fake_output = disc(disc_fake_input)\n",
    "                \n",
    "                # *** THIS IS THE FIX: Restored label smoothing from your original code ***\n",
    "                real_label = torch.ones_like(disc_real_output) * 0.9 \n",
    "                fake_label = torch.zeros_like(disc_fake_output)\n",
    "                \n",
    "                loss_d_real = criterion_adv(disc_real_output, real_label)\n",
    "                loss_d_fake = criterion_adv(disc_fake_output, fake_label)\n",
    "                loss_d = (loss_d_real + loss_d_fake) / 2\n",
    "            \n",
    "            scaler.scale(loss_d).backward()\n",
    "            scaler.step(opt_disc)\n",
    "\n",
    "            # -----------------\n",
    "            #  Train Generator (FROM ORIGINAL \"PERFECT\" CODE)\n",
    "            # -----------------\n",
    "            opt_gen.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
    "                disc_fake_input = torch.cat((thermal_img, fake_rgb), 1)\n",
    "                disc_fake_output = disc(disc_fake_input)\n",
    "                loss_g_gan_raw = criterion_adv(disc_fake_output, torch.ones_like(disc_fake_output))\n",
    "                loss_g_l1_raw = l1(fake_rgb, real_rgb)\n",
    "                loss_g_perceptual_raw = perceptual_loss(fake_rgb, real_rgb)\n",
    "                \n",
    "                loss_g_gan = loss_g_gan_raw * lambda_GAN\n",
    "                loss_g_l1 = loss_g_l1_raw * lambda_L1\n",
    "                loss_g_perceptual = loss_g_perceptual_raw * lambda_perceptual\n",
    "                loss_g = loss_g_gan + loss_g_l1 + loss_g_perceptual\n",
    "            \n",
    "            scaler.scale(loss_g).backward()\n",
    "            scaler.step(opt_gen)\n",
    "            scaler.update()\n",
    "            \n",
    "            # --- Update running losses and TQDM bar ---\n",
    "            g_loss_sum += loss_g.item()\n",
    "            d_loss_sum += loss_d.item()\n",
    "            loop.set_postfix(\n",
    "                G_Loss=f\"{loss_g.item():.4f}\",\n",
    "                D_Loss=f\"{loss_d.item():.4f}\",\n",
    "                G_L1=f\"{loss_g_l1.item():.4f}\"\n",
    "            )\n",
    "\n",
    "        # --- End of Epoch ---\n",
    "        scheduler_gen.step()\n",
    "        scheduler_disc.step()\n",
    "\n",
    "        avg_g_loss = g_loss_sum / len(train_loader)\n",
    "        avg_d_loss = d_loss_sum / len(train_loader)\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        current_lr = scheduler_gen.get_last_lr()[0]\n",
    "        \n",
    "        print(f\"\\n--- Epoch Summary: Part {part_idx}/{len(train_parts)} | Epoch {epoch}/{epochs_per_part} | Time: {epoch_time:.2f}s ---\")\n",
    "        print(f\"  Train Loss ‚Üí G: {avg_g_loss:.4f}, D: {avg_d_loss:.4f} | LR: {current_lr:.1e}\")\n",
    "\n",
    "        val_psnr, val_ssim = None, None # Initialize as None\n",
    "        \n",
    "        # --- Run Validation, Checkpointing, and Plotting ---\n",
    "        if epoch % 20 == 0 or epoch == epochs_per_part:\n",
    "            print(f\"  Running evaluation for epoch {epoch}...\")\n",
    "            \n",
    "            # --- Run Validation (uses new fast evaluate()) ---\n",
    "            val_psnr, val_ssim = evaluate(gen, val_loader, device=device)\n",
    "            print(f\"  Val Metrics ‚Üí PSNR: {val_psnr:.2f} dB, SSIM: {val_ssim:.4f}\")\n",
    "\n",
    "            # --- Checkpoint Saving ---\n",
    "            is_best = val_psnr > best_val_psnr\n",
    "            if is_best:\n",
    "                best_val_psnr = val_psnr # Update best score\n",
    "\n",
    "            state = {\n",
    "                'part': part_idx,\n",
    "                'epoch': epoch,\n",
    "                'gen_state_dict': gen.state_dict(),\n",
    "                'disc_state_dict': disc.state_dict(),\n",
    "                'opt_gen_state_dict': opt_gen.state_dict(),\n",
    "                'opt_disc_state_dict': opt_disc.state_dict(),\n",
    "                'val_history': val_history, # Pass the whole history\n",
    "            }\n",
    "            \n",
    "            save_checkpoint(state, is_best, part_idx, epoch)\n",
    "            \n",
    "            # --- Append to history and Plot ---\n",
    "            val_history.append({\n",
    "                \"part\": part_idx, \"epoch\": epoch, \n",
    "                \"psnr\": val_psnr, \"ssim\": val_ssim, \n",
    "                \"g_loss\": avg_g_loss, \"d_loss\": avg_d_loss\n",
    "            })\n",
    "            \n",
    "            graph_save_path = os.path.join(graph_dir, f\"graph_part_{part_idx}_epoch_{epoch}.png\")\n",
    "            plot_losses(val_history, save_path=graph_save_path) # Plot the full history\n",
    "        \n",
    "        else:\n",
    "            print(\"  Skipping evaluation, checkpointing, and graphing for this epoch.\")\n",
    "            # Append training losses, but None for validation metrics\n",
    "            val_history.append({\n",
    "                \"part\": part_idx, \"epoch\": epoch, \n",
    "                \"psnr\": None, # Append None\n",
    "                \"ssim\": None, # Append None\n",
    "                \"g_loss\": avg_g_loss, \"d_loss\": avg_d_loss\n",
    "            })\n",
    "\n",
    "    # Reset start_epoch to 1 for the next part (from original code)\n",
    "    start_epoch = 1\n",
    "\n",
    "print(\"\\nüéâ --- Training Finished --- üéâ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7086eec3-c2f8-4988-b03f-c91ac0c2d3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Loading best performing model for final evaluation ---\")\n",
    "\n",
    "# 1. Initialize a new generator\n",
    "# Ensure the Generator class definition is available\n",
    "try:\n",
    "    best_gen = Generator(in_channels=1, features=64).to(config[\"DEVICE\"])\n",
    "except NameError:\n",
    "    print(\"Error: The 'Generator' class is not defined.\")\n",
    "    print(\"Please ensure the cell containing the Generator class definition has been run.\")\n",
    "    # You might want to stop execution here or handle this error appropriately\n",
    "    best_gen = None \n",
    "\n",
    "if best_gen is not None:\n",
    "    # 2. Load the saved best checkpoint\n",
    "    # We use .get() for safety, though we know 'gen_state_dict' exists\n",
    "    try:\n",
    "        checkpoint = torch.load(config[\"BEST_CHECKPOINT_PATH\"], map_location=config[\"DEVICE\"])\n",
    "        best_gen.load_state_dict(checkpoint.get('gen_state_dict'))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Best checkpoint file not found at {config['BEST_CHECKPOINT_PATH']}\")\n",
    "        print(\"Please ensure training has run and 'checkpoints/best_model.pth' exists.\")\n",
    "        best_gen = None # Set to None so subsequent cells can check\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading best model: {e}\")\n",
    "        best_gen = None # Set to None so subsequent cells can check\n",
    "\n",
    "    if best_gen is not None:\n",
    "        # 3. Set the model to evaluation mode\n",
    "        best_gen.eval()\n",
    "        print(\"‚úÖ Best model loaded successfully and set to eval() mode.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4782a1-3336-46fb-91fc-62d5dc900ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm # Make sure tqdm is imported if not already\n",
    "\n",
    "# Note: We assume the torch-based metric functions (psnr_torch, ssim_torch, denorm01, create_window)\n",
    "# and the loss function (L1_LOSS) are already defined in your notebook from previous cells.\n",
    "\n",
    "if 'best_gen' in locals() and best_gen is not None:\n",
    "    print(\"üöÄ Starting final evaluation on the validation dataset (using best model)...\")\n",
    "\n",
    "    # Set the generator to evaluation mode (good practice, though already done)\n",
    "    best_gen.eval() \n",
    "\n",
    "    # Accumulators for our metrics\n",
    "    total_l1_loss = 0.0\n",
    "    total_psnr = 0.0\n",
    "    total_ssim = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    # We use config[\"DEVICE\"] for consistency\n",
    "    device = config[\"DEVICE\"]\n",
    "\n",
    "    # Pre-create the SSIM window and move it to the device once\n",
    "    ssim_window = None\n",
    "    try:\n",
    "        # Assumes create_window is defined\n",
    "        ssim_window = create_window(11, 3).float().to(device)\n",
    "    except NameError:\n",
    "        print(\"Warning: 'create_window' function is not defined. SSIM will not be calculated.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error creating SSIM window: {e}. SSIM will not be calculated.\")\n",
    "\n",
    "    # Disable gradients for evaluation\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(val_loader, desc=\"Evaluating Best Model\")\n",
    "        \n",
    "        # Define flags to only show helper function errors once\n",
    "        denorm_error_shown = False\n",
    "        metrics_error_shown = False\n",
    "        l1_error_shown = False\n",
    "\n",
    "        for thermal_img, real_rgb in loop:\n",
    "            # Move data to the device\n",
    "            thermal_img, real_rgb = thermal_img.to(device), real_rgb.to(device)\n",
    "\n",
    "            # Run the generator\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
    "                fake_rgb = best_gen(thermal_img) # Use best_gen\n",
    "                \n",
    "                # Calculate and accumulate L1 loss\n",
    "                try:\n",
    "                    loss_g_l1_raw = L1_LOSS(fake_rgb, real_rgb)\n",
    "                    total_l1_loss += loss_g_l1_raw.item() * thermal_img.size(0)\n",
    "                except NameError:\n",
    "                    if not l1_error_shown:\n",
    "                        print(\"Error: 'L1_LOSS' (nn.L1Loss) is not defined. L1 metric cannot be calculated.\")\n",
    "                        l1_error_shown = True\n",
    "                except Exception as e:\n",
    "                    if not l1_error_shown:\n",
    "                        print(f\"Error calculating L1 loss: {e}\")\n",
    "                        l1_error_shown = True\n",
    "\n",
    "            # Denormalize images *on the GPU* for PSNR/SSIM\n",
    "            try:\n",
    "                real_rgb_denorm = denorm01(real_rgb).float()\n",
    "                fake_rgb_denorm = denorm01(fake_rgb).float()\n",
    "            except NameError:\n",
    "                if not denorm_error_shown:\n",
    "                    print(\"Error: 'denorm01' function not defined. PSNR/SSIM cannot be calculated.\")\n",
    "                    denorm_error_shown = True\n",
    "                break # Stop evaluation loop if helpers are missing\n",
    "            except Exception as e:\n",
    "                if not denorm_error_shown:\n",
    "                    print(f\"Error during denorm: {e}\")\n",
    "                    denorm_error_shown = True\n",
    "                break\n",
    "                \n",
    "            # Calculate metrics for the whole batch on the GPU\n",
    "            try:\n",
    "                total_psnr += psnr_torch(real_rgb_denorm, fake_rgb_denorm, data_range=1.0).item() * thermal_img.size(0)\n",
    "                if ssim_window is not None:\n",
    "                    total_ssim += ssim_torch(real_rgb_denorm, fake_rgb_denorm, window=ssim_window, val_range=1.0).item() * thermal_img.size(0)\n",
    "            except NameError:\n",
    "                if not metrics_error_shown:\n",
    "                    print(\"Error: 'psnr_torch' or 'ssim_torch' not defined. Metrics cannot be calculated.\")\n",
    "                    metrics_error_shown = True\n",
    "                break # Stop evaluation loop\n",
    "            except Exception as e:\n",
    "                if not metrics_error_shown:\n",
    "                    print(f\"Error calculating metrics: {e}\")\n",
    "                    metrics_error_shown = True\n",
    "                break\n",
    "                \n",
    "            total_samples += thermal_img.size(0)\n",
    "\n",
    "    # Calculate the final averages\n",
    "    if total_samples > 0:\n",
    "        avg_l1 = total_l1_loss / total_samples\n",
    "        avg_psnr = total_psnr / total_samples\n",
    "        avg_ssim = total_ssim / total_samples if ssim_window is not None else 0.0\n",
    "\n",
    "        print(\"\\n\" + \"=\"*30)\n",
    "        print(\"‚úÖ Final 'Best Model' Results\")\n",
    "        print(\"=\"*30)\n",
    "        print(f\"Total Samples Evaluated: {total_samples}\")\n",
    "        if not l1_error_shown:\n",
    "            print(f\"Average L1 Loss:       {avg_l1:.4f}\")\n",
    "        if not metrics_error_shown and not denorm_error_shown:\n",
    "            print(f\"Average PSNR:          {avg_psnr:.2f} dB\")\n",
    "            if ssim_window is not None:\n",
    "                print(f\"Average SSIM:          {avg_ssim:.3f}\")\n",
    "        print(\"=\"*30)\n",
    "    elif not (denorm_error_shown or metrics_error_shown):\n",
    "        print(\"\\nEvaluation did not run. Check val_loader or other errors.\")\n",
    "else:\n",
    "    print(\"Skipping quantitative evaluation because 'best_gen' was not loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc751a2-25fd-413e-a278-2d04ca204155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "\n",
    "# This is the function definition\n",
    "def show_test_images(gen, loader, device, num_images=5):\n",
    "    \"\"\"\n",
    "    Visualizes the output of the generator on a few validation samples.\n",
    "    \"\"\"\n",
    "    gen.eval()  # Set the generator to evaluation mode\n",
    "    \n",
    "    # Get a batch of validation data\n",
    "    try:\n",
    "        t, r = next(iter(loader))\n",
    "    except StopIteration:\n",
    "        print(\"Data loader is empty.\")\n",
    "        return\n",
    "    except NameError:\n",
    "        print(\"Error: 'val_loader' is not defined.\")\n",
    "        return\n",
    "\n",
    "    t, r = t.to(device), r.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        fake_rgb = gen(t).detach().cpu()\n",
    "\n",
    "    # Denormalize images from [-1, 1] to [0, 1] for plotting\n",
    "    t = (t.cpu() + 1) / 2\n",
    "    r = (r.cpu() + 1) / 2\n",
    "    fake_rgb = (fake_rgb + 1) / 2\n",
    "    \n",
    "    # Ensure we don't try to show more images than are in the batch\n",
    "    num_images = min(num_images, len(t))\n",
    "\n",
    "    plt.figure(figsize=(15, num_images * 5))\n",
    "    plt.suptitle(\"Best Model Results\", fontsize=20) # Updated title\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Plot Input Thermal Image (convert grayscale to RGB for consistent display)\n",
    "        plt.subplot(num_images, 3, i * 3 + 1)\n",
    "        plt.imshow(t[i].permute(1, 2, 0).squeeze(), cmap='gray')\n",
    "        plt.title(\"Input Thermal\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Plot Generated RGB Image\n",
    "        plt.subplot(num_images, 3, i * 3 + 2)\n",
    "        plt.imshow(fake_rgb[i].permute(1, 2, 0))\n",
    "        plt.title(\"Generated RGB (Best Model)\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Plot Ground Truth RGB Image\n",
    "        plt.subplot(num_images, 3, i * 3 + 3)\n",
    "        plt.imshow(r[i].permute(1, 2, 0))\n",
    "        plt.title(\"Ground Truth RGB\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# --- Call the function ---\n",
    "if 'best_gen' in locals() and best_gen is not None:\n",
    "    print(\"--- Showing visual results from BEST model ---\")\n",
    "    try:\n",
    "        show_test_images(best_gen, val_loader, config[\"DEVICE\"], num_images=5)\n",
    "    except NameError as e:\n",
    "        print(f\"Error calling show_test_images: {e}\")\n",
    "        print(\"Please ensure 'val_loader' and 'config' are defined.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "else:\n",
    "    print(\"Skipping visual evaluation because 'best_gen' was not loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec7f049-1fb2-4e20-aa09-0310d8999e82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
